# 比较用于计算文本相似度的深度神经网络的模型与算法

## 文本相似度算法的研究背景与意义


文本相似度的计算是自然语言处理中一个重要的基础问题，自然语言处理中的许多任务都可以通过计算文本相似度来抽象为文本匹配任务，例如信息检索、机器翻译、自动问答等。
其中信息检索可以归结为查询项和文档的匹配，机器翻译可以归结为两种语言间的匹配，自动问答可以归结为问题与回复的匹配。


在网络化时代算法改变人们的工作和生活，其中文本相似度算法在网络日益渗透到人们生活方方面面的时代越来越重要，应用范围越来越普遍、所所不及，只要有知识或信息的环境就有可能用到这个算法，例如信息检索、机器翻译、自动问答等，其中信息检索可以归结为查询项和文档的相似度计算，机器翻译可以归结为两种语言间的相似度计算，自动问答可以归结为问题与回复的相似度计算。

在每一个领域的应用都是最基础的应用，没有文本相似度算法就没有更多的其它应用，其它各类应用都是建立在这个算法的基础上，这个算法能够在不同信息之间实现匹配，找到人们希望得到的信息，这就解决了海量知识与精准需求之间的矛盾，解决了快速检索需求与计算效率之间的矛盾，解决了人工操作费时费力与机器自动计算快捷高效之间的矛盾。当然随着网络规模越来越大，结构越来越复杂，联系越来越频繁，存储的内容越来越海量，对文本相似度算法的计算准确性和计算速度也提出了更高的要求，要求这些算法能够几乎在瞬间就可以精准找到检索的结果，在几乎实时就能够得到人们关注的结果，这样的话人们利用现代信息技术工作和生活的效率更高，更加人性化。这样看来，在前人的基础上深入研究文本相似度算法具有十分重要的意义。


## 相关的深度神经网络

近几年, 神经网络构建深度文本语义模型的方法得到广泛的应用, 取得一些重要的进展，这些神经网络模型具有强大的句子向量表示能力，利用这些句向量来计算文本的相似度成为了研究文本相似度算法的最流行的方法。

一般来说，这些神经网络模型实现文本相似度计算有交互式（Interaction-based）和特征式（Representation-based）两种方案。其中交互式模型是将两个文本拼接成单文本，然后计算两个文本词汇之间的交互(这种交互可以是标识值或者是语义相似值), 然后从交互矩阵中整合得出匹配分数。而特征式则是指将两个句子分别由编码器编码成两个稠密向量，然后计算两个向量间的相似度作为文本间的匹配度。通常情况下，交互式由于使得两个文本能够进行充分的比较，所以它准确性通常较好，但明显的缺点是在检索场景的效率较差；而特征式则可以提前计算并缓存好句向量，所以它有着较高的效率，但由于句子间的交互程度较浅，所以通常效果不如交互式。因此，为了确保模型实际应用的效率，本文主要研究基于特征式的深度文本匹配模型。


特征式代表模型：

DSSM(2013)

CDSSM(2014)

ARC I(2014)

Siamese Network(2016)

InferSent(2017)

BERT(2018)

Sentence-BERT(2019)

BERT-flow(2020)

SimCSE(2021)

ConSERT(2021)

CoSENT(2022)

由于2018年BERT模型在NLP界带来了翻天覆地的变化，此处不讨论和比较2018年之前的模型。
所以，本文主要调研了BERT(2018)，和比原生BERT更优、适合文本匹配的向量表示模型：Sentence-BERT(2019)、SimCSE(2021)。







## BERT

![bert-for-s](C:\Users\Yu\Desktop\论文\sbert\img\bert-for-s.png)

首先介绍 BERT，然后讨论相关的文本匹配神经网络。 BERT (Devlin et al., 2018) 是一个种基于深层 Transformer 的预训练模型，BERT 一经问世，就在多个自然语言处理任务中表现优异。而这正是由于 BERT 能够在大规模无标注文本中挖掘出丰富的语义信息，通过 BERT 模型得到上下文语义表示，再根据后续的任务进行计算。然而，使用BERT 原生模型做文本匹配任务缺点是不能对输入的两个句子独立计算对应的句向量,这使得原生 BERT 进行文本匹配变得困难。如图所示，Bert原生文本匹配模型常规做法是将匹配转换成二分类任务。输入的两个文本拼接成一个序列（中间用特殊符号“SEP”分割），经过12层 (base-model) 或24层 (large-model) Transformer 模块编码嵌入后，得到表示该文本序列语义表示的隐藏状态序列输出，将输出的隐藏状态序列取平均或者取 “CLS” 位置（序列的首位）作为文本的嵌入向量，经 softmax 完成最终分类作为相似度得分。

## SentenceBERT

![image-20220614160914121](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614160914121.png)

Sentence-BERT作者 NilsReimers在实验中指出，这样的做法产生的结果并不理想（至少在处理语义检索和聚类问题时是如此），甚至比Glove词向量取平均的效果还差。为了让Bert更好地利用文本信息，作者们在论文中提出了如下的SBert孪生网络模型。SBert使用了孪生网络的结构，文本Encoder部分用同一个Bert来处理。之后，作者分别实验了CLS-token和2种池化策略（Avg-Pooling、Mean-Pooling），对Bert输出的隐藏状态序列进一步特征提取、压缩，得到分别表示2个句子向量的u,v。针对2分类（文本匹配）任务，将u、v拼接成（u,v,|u-v|），接入全连接网络，经softmax分类输出获取分类目标O（作为相似度得分）,随后的损失函数用交叉熵计算。在推理阶段，SBert则是直接计算余弦相似度，这虽然缩短了预测时间，却导致了模型在训练和推理的不一致性。



Sentence-BERT终究是训练和预测不一致的方案，所以存在一定的概率会“训崩”，具体表现为训练loss还在下降，训练acc还在提升，但是基于余弦值的评测指标（如Spearman系数）却明显下降，哪怕是训练集也是如此。这说明训练还是正常进行的，但是已经脱离了“正样本对的u−vu−v更小、负样本对的u−vu−v更大”的分类依据，从而余弦值就崩了。



Sentence-BERT还存在调优困难问题，这同样是因为训练和预测的不一致性，导致我们很难确定对哪些训练过程的调整会给预测结果带来正面帮助。



## SimCSE

Bert encode出来的向量表达具有各向异性
什么叫各向异性？举个例子，一些电阻原件，正接是良导体，反接是绝缘体或者电阻很大，沿不同方向差异很大。在bert出来的向量中表现为，用不同的方式去衡量它，他表现出不同的语义，差别很大，也就是不能完整的衡量出bert向量中全部语义信息
分布不均匀，低频词分布稀疏，高频词分布紧密。
也就是高频词会集中在头部，离原点近，低频词会集中在尾部，离远点远高频词与低频词分布在不同的区域，那高频词与低频词之间的相识度也就没法计算了。这也反映出来的就是明显的低频词没有得到一个很好的训练。同时，高频词频次高，也会主宰句子表达。





## 数据集与评测指标



本文实验所采用的**数据集**为：

<center>表1：数据集的大小、任务、语言、领域的详细信息</center>

![image-20220614210327197](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210327197.png)



Chinese-STS-B(The Semantic Textual Similarity Benchmark,语义文本相似性基准测试)，是从新闻标题、视频标题、图像标题以及自然语言推断数据中提取的句子对的集合，每对都是由人工标注的，用于语义文本相似度的任务。共包含0到5的6个标签，数字越大表示文本对越相似。



LCQMC（A Large-scale Chinese Question Matching Corpus）来自哈尔滨工业大学（深圳），该数据集由从百度知道不同领域的用户问题中抽取构建，是百度知道的中文问题的语义匹配数据集。



BQ（the Bank Question corpus），中文句子语义等价识别（SSEI）语料库，包含了来自一整年的银行在线服务日志的 120,000 个问题对。



PAWSX（Paraphrase Adversaries from Word Scrambling），该数据集包含 23,659 个人工翻译的 PAWS 评估对和 296,406 个机器翻译的训练对，采用六种类型不同的语言：法语、西班牙语、德语、中文、日语和韩语。 所有翻译的对都来自 PAWS-Wiki 中的示例。



本文所使用的数据集都是有监督的任务，数据的结构是(句子一, 句子二, 相似度标签)。 相似度标签表示两个句子的相似度得分。

使用斯皮尔曼相关系数 ρ（Spearman rank correlation） 作实验指标，其计算方式如下：

![image-20220614200337838](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614200337838.png)

![image-20220614200328539](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614200328539.png)

对于上式，di 是 标签值 和 余弦相似度 之间的差值。n 是数据集的总量。 斯皮尔曼相关系数 ρ仅取决于余弦相似度和标签值的相对顺序，适用于评估模型在语义文本相似度任务上的性能。 与其他相关系数一样，该系数在 -1 和 +1 之间变化，0 表示没有相关性。 系数值越大的意味着预测值与标签值相关性越大。



## 实验



### 参数设置

![image-20220614210143539](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210143539.png)



### 实验结果

![image-20220614210205118](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210205118.png)





### 实验分析







