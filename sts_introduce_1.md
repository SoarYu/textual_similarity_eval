# 比较用于计算文本相似度的深度神经网络的模型与算法

## 文本相似度算法的研究背景与意义


文本相似度的计算是自然语言处理中一个重要的基础问题，自然语言处理中的许多任务都可以通过计算文本相似度来抽象为文本匹配任务，例如信息检索、机器翻译、自动问答等。
其中信息检索可以归结为查询项和文档的匹配，机器翻译可以归结为两种语言间的匹配，自动问答可以归结为问题与回复的匹配。


在网络化时代算法改变人们的工作和生活，其中文本相似度算法在网络日益渗透到人们生活方方面面的时代越来越重要，应用范围越来越普遍、所所不及，只要有知识或信息的环境就有可能用到这个算法，例如信息检索、机器翻译、自动问答等，其中信息检索可以归结为查询项和文档的相似度计算，机器翻译可以归结为两种语言间的相似度计算，自动问答可以归结为问题与回复的相似度计算。

在每一个领域的应用都是最基础的应用，没有文本相似度算法就没有更多的其它应用，其它各类应用都是建立在这个算法的基础上，这个算法能够在不同信息之间实现匹配，找到人们希望得到的信息，这就解决了海量知识与精准需求之间的矛盾，解决了快速检索需求与计算效率之间的矛盾，解决了人工操作费时费力与机器自动计算快捷高效之间的矛盾。当然随着网络规模越来越大，结构越来越复杂，联系越来越频繁，存储的内容越来越海量，对文本相似度算法的计算准确性和计算速度也提出了更高的要求，要求这些算法能够几乎在瞬间就可以精准找到检索的结果，在几乎实时就能够得到人们关注的结果，这样的话人们利用现代信息技术工作和生活的效率更高，更加人性化。这样看来，在前人的基础上深入研究文本相似度算法具有十分重要的意义。


## 相关的深度神经网络

近几年, 神经网络构建深度文本语义模型的方法得到广泛的应用, 取得一些重要的进展，这些神经网络模型具有强大的句子向量表示能力，利用这些句向量来计算文本的相似度成为了研究文本相似度算法的最流行的方法。

一般来说，这些神经网络模型实现文本相似度计算有交互式（Interaction-based）和特征式（Representation-based）两种方案。其中交互式模型是将两个文本拼接成单文本，然后计算两个文本词汇之间的交互(这种交互可以是标识值或者是语义相似值), 然后从交互矩阵中整合得出匹配分数。而特征式则是指将两个句子分别由编码器编码成两个稠密向量，然后计算两个向量间的相似度作为文本间的匹配度。通常情况下，交互式由于使得两个文本能够进行充分的比较，所以它准确性通常较好，但明显的缺点是在检索场景的效率较差；而特征式则可以提前计算并缓存好句向量，所以它有着较高的效率，但由于句子间的交互程度较浅，所以通常效果不如交互式。因此，为了确保模型实际应用的效率，本文主要研究基于特征式的深度文本匹配模型。


特征式代表模型：

DSSM(2013)

CDSSM(2014)

ARC I(2014)

Siamese Network(2016)

InferSent(2017)

BERT(2018)

Sentence-BERT(2019)

BERT-flow(2020)

SimCSE(2021)

ConSERT(2021)

CoSENT(2022)

由于2018年BERT模型在NLP界带来了翻天覆地的变化，此处不讨论和比较2018年之前的模型。
所以，本文主要调研了BERT(2018)，和比原生BERT更优、适合文本匹配的向量表示模型：Sentence-BERT(2019)、SimCSE(2021)。







## BERT

![bert-for-s](C:\Users\Yu\Desktop\论文\sbert\img\bert-for-s.png)

首先介绍 BERT，然后讨论相关的文本匹配神经网络。 BERT (Devlin et al., 2018) 是一个种基于深层 Transformer 的预训练模型，BERT 一经问世，就在多个自然语言处理任务中表现优异。而这正是由于 BERT 能够在大规模无标注文本中挖掘出丰富的语义信息，通过 BERT 模型得到上下文语义表示，再根据后续的任务进行计算。然而，使用BERT 原生模型做文本匹配任务缺点是不能对输入的两个句子独立计算对应的句向量,这使得原生 BERT 进行文本匹配变得困难。如图所示，Bert原生文本匹配模型常规做法是将匹配转换成二分类任务。输入的两个文本拼接成一个序列（中间用特殊符号“SEP”分割），经过12层 (base-model) 或24层 (large-model) Transformer 模块编码嵌入后，得到表示该文本序列语义表示的隐藏状态序列输出，将输出的隐藏状态序列取平均或者取 “CLS” 位置（序列的首位）作为文本的嵌入向量，经 softmax 完成最终分类作为相似度得分。

## SentenceBERT

![image-20220614160914121](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614160914121.png)

Sentence-BERT作者 NilsReimers在实验中指出，这样的做法产生的结果并不理想（至少在处理语义检索和聚类问题时是如此），甚至比Glove词向量取平均的效果还差。为了让Bert更好地利用文本信息，作者们在论文中提出了如下的SBert孪生网络模型。SBert使用了孪生网络的结构，文本Encoder部分用同一个Bert来处理。之后，作者分别实验了CLS-token和2种池化策略（Avg-Pooling、Mean-Pooling），对Bert输出的隐藏状态序列进一步特征提取、压缩，得到分别表示2个句子向量的u,v。针对2分类（文本匹配）任务，将u、v拼接成（u,v,|u-v|），接入全连接网络，经softmax分类输出获取分类目标O（作为相似度得分）,随后的损失函数用交叉熵计算。在推理阶段，SBert则是直接计算余弦相似度，这虽然缩短了预测时间，却导致了模型在训练和推理的不一致性。



Sentence-BERT终究是训练和预测不一致的方案，所以存在一定的概率会“训崩”，具体表现为训练loss还在下降，训练acc还在提升，但是基于余弦值的评测指标（如Spearman系数）却明显下降，哪怕是训练集也是如此。这说明训练还是正常进行的，但是已经脱离了“正样本对的u−vu−v更小、负样本对的u−vu−v更大”的分类依据，从而余弦值就崩了。



Sentence-BERT还存在调优困难问题，这同样是因为训练和预测的不一致性，导致我们很难确定对哪些训练过程的调整会给预测结果带来正面帮助。



## SimCSE


SimCSE 全称是 Simple Contrastive Learning of Sentence Embeddings, 意为：通过⼀种简单的对⽐学习去做句⼦嵌⼊。 与前面两个模型的最大不同之处的，SimCSE使用了对比学习的思想来进行句向量的生成，即使在无监督的情况下，也可以⽣成质量较好的句⼦向量。在介绍SimCSE之前，我们先来了解⼀个叫对⽐学习的东西。对⽐学习顾名思义就是需要通过对⽐来学习，在计算文本语义相似度的任务中表现为：尽可能地提高正样本间的余弦相似度，同时降低负样本的余弦相似度，来构造一个优质的语义表示空间。使用alignment(对齐)和uniformity(均匀)来衡量效果。对齐这个指标和句向量相似的衡量一致，而均匀这个指标就是bert-flow中向量均匀分布的要求一致。

SimSCE 的相似样本的构造经过实验比较采用了dropout mask的方法，尽管这种构建样本的⽅法⾮常的简单，但是却能够产⽣奇效。
 
接着之前的句向量表示模型进行相似句计算的方法，这篇接着介绍一种新的方法-SimCSE。文章来自普林斯顿陈丹琦，引入了对比学习的思想进行sentence embedding的学习，刷爆了无监督与有监督语义相似度计算任务，成为SOTA，甚至本文的无监督方法超过了其他有监督方法的效果，还是很惊艳的。对比学习的思想是拉近相似样本，推开不相似的样本。相似样本的构造经过实验比较采用了dropout mask的方法。

之前的sentence embedding的方法主要是前面介绍的SBERT(孪生网络的形式)和对生成的向量进行分布归整的方法:bert-flow等。对比学习的目标就是学习一个优质的语义表示空间，使用alignment(对齐)和uniformity(均匀)来衡量效果。对齐这个指标和句向量相似的衡量一致，而均匀这个指标就是bert-flow中向量均匀分布的要求一致。


今年NLP 领域出现了⼀个⽐较⽕的模型叫SimCSE,⽂章的全称是Simple Contrastive Learning of Sentence Embeddings。直译过来就是：
通过⼀种简单的对⽐学习去做句⼦嵌⼊。⽽且在可以不要监督数据的情况下，⽣成质量较好的句⼦向量。以往⽆论是word2vec词向量做平均，还
是预训练的bert⽣成的句⼦向量等⽆监督的⽅式⽣成的句⼦向量都不是太好。SimSCE可以算在⽆监督句向量的抽取领域⼜往前迈了⼀步。
对⽐学习
在介绍SimCSE之前，我们先来了解⼀个叫对⽐学习的东西。对⽐学习顾名思义就是需要通过对⽐来学习，这⾥笔者拿图像领域的特征抽取来介绍
⼀下对⽐学习的整个过程，如下图所⽰：
（1）将⼀只猫的图X，数据增强的⽅式⽣成另⼀张猫的图⽚作为正例X+，构建正例样本对，选择⼀只狗作为负例X-。
（2）将这个正负例样本组（X,X+,X-）同时输⼊到⼀个模型中进⾏特征抽取。
（3）优化对⽐损失，将X和X+的在特征空间⾥⾯的距离拉近，同时将X和X-在特征空间中的距离拉远。
这样整个对⽐学习的过程就介绍完了，通过对⽐学习我们就可以得到⾼质量的特征表⽰。⾄于如何构建正负例样本组（X,X+,X-），如何两个样本
在衡量样本空间距离等，都是值得探索和思考的问题。



SimSCE的设计思路
⽽SimSCE 就是⼀个采⽤对⽐学习框架进⾏句⼦嵌⼊的⽅法，SimCES提出了有监督和⽆监督这两种对⽐学习⽅式来进⾏句⼦嵌⼊。只不过
SimSCE 构建正例样本的⽅法⾮常的简单，但是却能够产⽣奇效。那我们就来看看SimCSE 到底是如何构建正样本对的

如上图所⽰，过程如下：
(1) 由于数据集中存在标注好的相似数据，这⾥只需要做⼀个简单的负采样，构造（X,X+,X-）三元组。
(2) 然后将这个（X,X+,X-）同时输⼊到⽂本向量抽取的模型中进⾏特征抽取。
(3) 优化对⽐损失,增加正例之间的相似度，减⼩负例之间的相似度。


有监督的SimCSE的Loss 详解
这⾥假设每个batch 输⼊给模型的样本 格式如下 ：
（1） [0,1,2,3,4,5] 代表⼀个batch中含有六个样本
（2）[(0,1,2),(3,4,5)]代表⼆组样本，其中0,1是相似句⼦代表正例，0,2是不相似的句⼦代表负例；其中3,4是相似句⼦代表正例，3,5是不相似的
句⼦代表负例
同意模型的输出 y_pred 就是[X0,X1,X2,X3,X4,X5] 这六个句⼦的向量表⽰。
对⽐Loss 的详解 如下。


结语
其实除了通过dropout 两次来构造对⽐学习的正例样本，其实还有很多的⽅式构造正例，⽐如可以采⽤⽂本处理⾥⾯经常⽤到的同义词替换，回
译等⽅式去进⾏正例构造，但SimCSE的作者想到⽤dropout这么简单的⽅式来构建对⽐学习的正例样本对，并且在很多数据集上表现不俗，不得
不感叹⼀句——⼤道⾄简。







## 数据集与评测指标



本文实验所采用的**数据集**为：

<center>表1：数据集的大小、任务、语言、领域的详细信息</center>

![image-20220614210327197](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210327197.png)



Chinese-STS-B(The Semantic Textual Similarity Benchmark,语义文本相似性基准测试)，是从新闻标题、视频标题、图像标题以及自然语言推断数据中提取的句子对的集合，每对都是由人工标注的，用于语义文本相似度的任务。共包含0到5的6个标签，数字越大表示文本对越相似。



LCQMC（A Large-scale Chinese Question Matching Corpus）来自哈尔滨工业大学（深圳），该数据集由从百度知道不同领域的用户问题中抽取构建，是百度知道的中文问题的语义匹配数据集。



BQ（the Bank Question corpus），中文句子语义等价识别（SSEI）语料库，包含了来自一整年的银行在线服务日志的 120,000 个问题对。



PAWSX（Paraphrase Adversaries from Word Scrambling），该数据集包含 23,659 个人工翻译的 PAWS 评估对和 296,406 个机器翻译的训练对，采用六种类型不同的语言：法语、西班牙语、德语、中文、日语和韩语。 所有翻译的对都来自 PAWS-Wiki 中的示例。



本文所使用的数据集都是有监督的任务，数据的结构是(句子一, 句子二, 相似度标签)。 相似度标签表示两个句子的相似度得分。

使用斯皮尔曼相关系数 ρ（Spearman rank correlation） 作实验指标，其计算方式如下：

![image-20220614200337838](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614200337838.png)

![image-20220614200328539](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614200328539.png)

对于上式，di 是 标签值 和 余弦相似度 之间的差值。n 是数据集的总量。 斯皮尔曼相关系数 ρ仅取决于余弦相似度和标签值的相对顺序，适用于评估模型在语义文本相似度任务上的性能。 与其他相关系数一样，该系数在 -1 和 +1 之间变化，0 表示没有相关性。 系数值越大的意味着预测值与标签值相关性越大。



## 实验



### 参数设置

![image-20220614210143539](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210143539.png)

The parameter settings during training.


The main parameter settings during the training of CoSBERT are shown in Table 1. AdamW is used as the optimizer, and the optimizer parameters are set to the
default parameters. In order to slow down the model overfitting,  10\% of the training data is used as a warmup,  and the training is performed until the model converges. The default pooling strategy is MEAN.


### 实验结果

![image-20220614210205118](C:\Users\Yu\AppData\Roaming\Typora\typora-user-images\image-20220614210205118.png)
我们评估了我们的模型在上述数据集中的表现，并与其他方法进行了对比。实验结果均只用该数据集的train部分训练，并在该数据集test部分上评估得到的表现，没用外部数据。将不同预训练模型按不同方法微调（fine-tuned）后，实验结果如表1所示.
实验结果均只在各自数据集的train训练并在test上评估得到的表现。得分采用句子对的余弦相似度值和真实标签值之间的Spearman斯皮尔曼相关系数ρ × 100, and Scores are based on a 10-fold cross-validation.




### 实验分析

实验结果显示，通过对比不同预训练模型在不同数据集上的表现，我们的方案在all tasks上都有较为明显的提升，原生训练的平均提升幅度接近8\%,取得了最高的平均分数。由此可见，在训练阶段直接优化句子对的cos距离值的方案是有效的，得到的模型是可用于文本匹配任务的。

进一步分析在单个数据集下对不同模型的提升情况，我们选择了更贴近下游应用系统的SCHOLAT数据集来训练，并在不同数据集的test部分评估不同模型的表现。得到的结果如表2所示。

实验结果显示，整个过程中所有的模型在PAWSX上得分都是偏低的，这是因为PAWSX的负样本几乎都是词语相同但语义却不同的负样本，需要更深层的交互才能更好地识别出来，这也是特征式语义匹配模型的先天不足。但是除开PAWSX任务，我们的模型在其他任务上都取得了最高得分，这也进一步说明其对下游任务是有效的。


在前面的实验中，我们已经证明了我们模型的优秀性能。在这节中，我们主要评估本文前面提到的池化策略(CLS,FLA,MEAN)对模型表现的影响，以便更好地了解哪个更适合我们的模型来完成文本匹配任务。因此，在消融实验中，我们使用了不同的预训练模型按我们的优化方案微调，并在各数据集中评估了不同池化策略对模型的影响，实验结果如表3所示。

在前面的实验中，我们已经证明了我们模型的优秀性能。在这节中，我们主要评估了模型的池化策略(CLS,FLA,MEAN)和损失函数中

对模型表现的影响，以便更好地了解哪个更适合我们的模型来完成文本匹配任务。因此，在消融实验中，我们使用了不同的预训练模型按我们的优化方案微调，并在各数据集中评估了不同池化策略对模型的影响，实验结果如表3所示。



由实验结果可以看出，不同的池化策略总体表现相差不大，最大值与最小值差距仅为1.77\%,We observe that the pooling strategy has a small impact.进一步看，The FLA strategy perform worse than MEAN or CLS-token strategy，MEAN是得分最高的，因此我们选择MEAN作为the default model configuration.

## 总结


    




